{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping walkthrough for LegendsArceus...\n",
      "Saved walkthroughs\\LegendsArceus\\Part 1.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 2.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 3.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 4.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 5.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 6.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 7.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 8.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 9.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 10.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 11.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 12.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 13.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 14.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 15.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 16.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Part 17.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Requests: Part 1.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Requests: Part 2.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Requests: Part 3.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Requests: Part 4.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Spiritomb Wisps.txt\n",
      "Saved walkthroughs\\LegendsArceus\\Unown Locations.txt\n",
      "Finished scraping LegendsArceus\n",
      "\n",
      "Scraping walkthrough for Scarlet_and_Violet...\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 1.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 2.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 3.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 4.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 5.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 5.5.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 6.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 6.5.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 6.5.2.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 7.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 7.5.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 8.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 8.5.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 8.5.2.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 9.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 10.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 11.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 12.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 13.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 14.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 15.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 15.5.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 15.5.2.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 16.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 17.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 18.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 19.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 20.txt\n",
      "Saved walkthroughs\\Scarlet_and_Violet\\Part 21.txt\n",
      "Finished scraping Scarlet_and_Violet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "def get_html(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "def parse_walkthrough_parts(game_url):\n",
    "    html_content = get_html(game_url)\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    parts = []\n",
    "\n",
    "    table = soup.find('table', {'class': 'roundy'})\n",
    "\n",
    "    if table:\n",
    "        for row in table.find_all('tr', {'style': 'background: #FFF;'}):\n",
    "            part = row.find('th')\n",
    "            keywords = row.find('td')\n",
    "            if part and keywords:\n",
    "                part_name = part.get_text(strip=True)\n",
    "                part_url = 'https://bulbapedia.bulbagarden.net' + part.find('a')['href']\n",
    "                keywords_text = keywords.get_text(strip=True)\n",
    "                parts.append((part_name, part_url, keywords_text))\n",
    "\n",
    "    return parts\n",
    "\n",
    "def scrape_walkthrough_text(part_url):\n",
    "    html_content = get_html(part_url)\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    walkthrough_div = soup.find('div', class_='mw-parser-output')\n",
    "    if walkthrough_div:\n",
    "        walkthrough_text = walkthrough_div.get_text(separator='\\n', strip=True)\n",
    "        return walkthrough_text\n",
    "    return \"\"\n",
    "\n",
    "def scrape_core_game_walkthrough(core_game_url):\n",
    "    parts = parse_walkthrough_parts(core_game_url)\n",
    "    walkthrough_data = []\n",
    "\n",
    "    for part_name, part_url, keywords in parts:\n",
    "        text = scrape_walkthrough_text(part_url)\n",
    "        walkthrough_data.append({\n",
    "            'Part': part_name,\n",
    "            'URL': part_url,\n",
    "            'Keywords': keywords,\n",
    "            'Text': text\n",
    "        })\n",
    "        sleep(1)  # To avoid overwhelming the server\n",
    "\n",
    "    return walkthrough_data\n",
    "\n",
    "def save_walkthrough_as_text(game_name, walkthrough_data):\n",
    "    folder_path = os.path.join('walkthroughs', game_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    for part in walkthrough_data:\n",
    "        filename = os.path.join(folder_path, f\"{part['Part'].replace('/', '_')}.txt\")\n",
    "        \n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(f\"Part: {part['Part']}\\n\")\n",
    "            file.write(f\"URL: {part['URL']}\\n\")\n",
    "            file.write(f\"Keywords: {part['Keywords']}\\n\\n\")\n",
    "            file.write(\"Walkthrough Text:\\n\")\n",
    "            file.write(part['Text'])\n",
    "        \n",
    "        print(f\"Saved {filename}\")\n",
    "\n",
    "def main():\n",
    "    core_games = [\n",
    "        ('LegendsArceus', 'https://bulbapedia.bulbagarden.net/wiki/Appendix:Legends:_Arceus_walkthrough'),\n",
    "        ('Scarlet_and_Violet', 'https://bulbapedia.bulbagarden.net/wiki/Appendix:Scarlet_and_Violet_walkthrough')\n",
    "    ]\n",
    "\n",
    "    # Create the main walkthroughs folder if it doesn't exist\n",
    "    if not os.path.exists('walkthroughs'):\n",
    "        os.makedirs('walkthroughs')\n",
    "\n",
    "    for game_name, game_url in core_games:\n",
    "        print(f\"Scraping walkthrough for {game_name}...\")\n",
    "        walkthrough_data = scrape_core_game_walkthrough(game_url)\n",
    "        save_walkthrough_as_text(game_name, walkthrough_data)\n",
    "        print(f\"Finished scraping {game_name}\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1081, which is longer than the specified 1000\n",
      "Created a chunk of size 1067, which is longer than the specified 1000\n",
      "Created a chunk of size 1236, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test vectorstore created and saved successfully!\n",
      "Full vectorstore created and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def load_and_embed_walkthroughs(file_paths: List[str]) -> FAISS:\n",
    "    documents = []\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                # Extract metadata from the content\n",
    "                lines = content.split('\\n')\n",
    "                metadata = {\n",
    "                    'game': lines[0].split(': ')[1],\n",
    "                    'part': lines[1].split(': ')[1],\n",
    "                    'keywords': lines[2].split(': ')[1],\n",
    "                    'file_name': os.path.basename(file_path)\n",
    "                }\n",
    "                # Create a Document with the content and metadata\n",
    "                doc = Document(page_content=content, metadata=metadata)\n",
    "                documents.append(doc)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "# Test with the first 4 files\n",
    "test_files = [\n",
    "    r\"walkthrough_rewrites\\Black_and_White\\Black_and_White - Part 1 - Introduction, Nuvema Town, Juniper's Lab, Route 1, Accumula Town.txt\",\n",
    "    r\"walkthrough_rewrites\\Black_and_White\\Black_and_White - Part 2 - Route 2, Striaton City, The Dreamyard, Striaton Gym.txt\",\n",
    "    r\"walkthrough_rewrites\\Black_and_White\\Black_and_White - Part 3 - Route 3, Wellspring Cave, Nacrene City, Nacrene Gym.txt\",\n",
    "    r\"walkthrough_rewrites\\Black_and_White\\Black_and_White - Part 4 - Pinwheel Forest, Skyarrow Bridge, Castelia City, Castelia Gym.txt\"\n",
    "]\n",
    "\n",
    "# Create and save the test vectorstore\n",
    "test_vectorstore = load_and_embed_walkthroughs(test_files)\n",
    "test_vectorstore.save_local(\"test_vectorstore\")\n",
    "\n",
    "print(\"Test vectorstore created and saved successfully!\")\n",
    "\n",
    "# Function to get all walkthrough files\n",
    "def get_all_walkthrough_files(root_dir: str) -> List[str]:\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                all_files.append(os.path.join(root, file))\n",
    "    return all_files\n",
    "\n",
    "# Uncomment the following lines when ready to process all files\n",
    "all_walkthrough_files = get_all_walkthrough_files('walkthrough_rewrites')\n",
    "full_vectorstore = load_and_embed_walkthroughs(all_walkthrough_files)\n",
    "full_vectorstore.save_local(\"full_vectorstore\")\n",
    "print(\"Full vectorstore created and saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
